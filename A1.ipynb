{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sir4OIRs5gAX",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 1: Understanding the Literature: \"A Mathematical Theory of Communication\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tM2r_vwS6QT3",
        "colab_type": "text"
      },
      "source": [
        "##Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnfJ1PKv6uWc",
        "colab_type": "text"
      },
      "source": [
        "“A Mathematical Theory of Communication” was written by C. E. Shannon and published in The Bell System Technical Journal, 1948. It has been cited more than 5000 times since published. In this paper, I will briefly describe the content of this journal and introduce what creative views they presented. On the other hand, I also will express my own opinion about this journal. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6gcfUno6_n5",
        "colab_type": "text"
      },
      "source": [
        "## Content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlDckJNh7EOD",
        "colab_type": "text"
      },
      "source": [
        "Professor Shannon added some new factors into the mathematical theory of communication and emphatically introduced the influence of noise in the channel in this paper. Meanwhile, he also claimed the possibility of loss reduction between original message and final information, because of the difference of the statistical structure of the original message and the nature of the final destination of the information. The communication system had been categorized roughly into three major classifications according to the statement of Professor Shannon, they are discrete, continuous and mixed systems. In short, a discrete system refers to the system in which both information and signals are discrete sequences of symbols while the information and signals are both treated as continuous functions in a continuous system. “Mixed system” is what it literally means, it mixes both discrete system and continuous system. Taking some examples from real world, discrete system can be involved in telegraphy, radio and television base on continuous system, PCM transmission of speech uses mixed system."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "us34o2rp7Hll",
        "colab_type": "text"
      },
      "source": [
        "Professor Shannon had presented a fundamental problem of communication in this paper. The problem refers to how the message at a point can be duplicated exactly or approximately at another point. A communication system may contain five basic parts: information source, transmitter, channel, receiver and destination. Massages can be generated in information source part which would be communicated to a receiving terminal. Transmitter will operate the massages to turn them into a single that can pass through channel part and finally the single will be reversed into message. The destination is the one to which the message is sent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEEQw3Ds7KPz",
        "colab_type": "text"
      },
      "source": [
        "For the problem, he had claimed some theorems in this paper in general. His theorems are existence, in other word, there are no specific coding implementation shown in content. Those theorems are proved through mathematic calculation. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyJxLw4D7MJV",
        "colab_type": "text"
      },
      "source": [
        "##Innovation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbtzkhmt7RPH",
        "colab_type": "text"
      },
      "source": [
        "In this paper, Professor Shannon had stated three theorems, called Shannon’s three theorems future, these theorems became the fundament of the information theory since 1948. Also, it provides a direction of communication information research (AffeldtEmail, et al 2014). This could be the biggest innovation of this paper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOAmJ79U7WVz",
        "colab_type": "text"
      },
      "source": [
        "#### Shannon's first theorem:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6BCnkCD7epm",
        "colab_type": "text"
      },
      "source": [
        "Shannon’s first theorem is a variable-length undistorted source coding theorem (Har-Peled, 2009). If we set a discrete memoryless source X contains N symbols {$x_{1},x_{2},…,x_{i},…,x_{N}$}, and this source can emits K multiple symbol sequences, then the source can sent $N^K$ different symbol sequence messages, where the occurrence probability of the $Jth$ symbol sequence message is $PK_{j}$. The length of binary code obtained after the source coding is $B_{j}$, and the average length of the code group B is "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcPQc9Rc7lyq",
        "colab_type": "text"
      },
      "source": [
        "$$B =PK_{1}B_{1}+PK_{2}B_{2}+…+PK_{N^k}B_{N^k}.$$ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDwj8AN97mNS",
        "colab_type": "text"
      },
      "source": [
        "therefore, as K goes to infinity, the relationship between B and the amount of information H(X) is B/ K =H(X), where k goes to infinity. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJaC_5OoJsi5",
        "colab_type": "text"
      },
      "source": [
        "The meaning of first theorem is to convert the original symbol of source into the new symbol of code and make the code symbol obey the same distribution as much as possible. Thereby the source information can be transmitted with fewer symbol because each code symbol can carry the most amount of information. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0inWIeItJvPR",
        "colab_type": "text"
      },
      "source": [
        "####Shannon’s second theorem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuY5BVYAKMth",
        "colab_type": "text"
      },
      "source": [
        "Shannon’s second theorem is the noisy channel coding theorem (Har-Peled, 2009). When the information transmission rate of the channel is less than the capacity of the channel, an arbitrary high transmission reliability can be achieved by adopting appropriate channel coding methods. However, if the information transmission rate exceeds the capacity of the channel, reliable transmission cannot be achieved."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeTHLa-HKQyI",
        "colab_type": "text"
      },
      "source": [
        "The capacity $C$ of a noisy channel can be defined by $C = Max(H(x) - Hy(x))$, where the maximum is about all possible sources of information used as channel input. In this theory, the capacity of a channel of band W perturbed by an arbitrary noise is bounded by the inequalities. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37MOqfXOKT_o",
        "colab_type": "text"
      },
      "source": [
        "$$W*\\frac {log(P+N_{1})}{N_{1}}≤C ≤W* \\frac {log(P+N)}{N_{1}}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDbq41VvMURi",
        "colab_type": "text"
      },
      "source": [
        "Where $P$ is average transmitter power, $N$ is average noise power, $N1$ is entropy power of the noise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1GWJ4t8MWbZ",
        "colab_type": "text"
      },
      "source": [
        "If $N = N_{1}$, in other word, the noise itself is white, the formula above can be："
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3E5hxTJhMZz1",
        "colab_type": "text"
      },
      "source": [
        "$$C=W*log(1+ \\frac {P}{N})$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_KORTM5Mg24",
        "colab_type": "text"
      },
      "source": [
        "####Shannon’s third theorem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zna25CpXMmL7",
        "colab_type": "text"
      },
      "source": [
        "Shannon’s third theorem is a distortion-free coding theorem (Har-Peled, 2009). It refers to a such source code that an encoded information transmission ratee is slightly greater than the rate distortion function, meanwhile the average distortion degree of the code is no larger than the given allowable distortion degree, that can be represented as $D’<=D$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhzgB1BmM2kG",
        "colab_type": "text"
      },
      "source": [
        "The Shannon’s three theorems are the main innovations in his paper, and this bring a huge influence on the communication area, most of current researches base on his theory to develop."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJEfJksINHzV",
        "colab_type": "text"
      },
      "source": [
        "##Technical Quality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OP7gI2BFNKIJ",
        "colab_type": "text"
      },
      "source": [
        "After reading this paper, I believe this is a high technical quality book with clear explanation, classified main points and rigorous proof process. All the points he mentioned are clarified thoughtfully and carefully. In the introduction section, he had provided a background about his research, and what tool used in his researches. After introduction, he used several parts to state and prove his main point clearly, which were the three theorems I introduced above. His pints and proof process are comprehensively shown in each part. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vCumra_NNJ5",
        "colab_type": "text"
      },
      "source": [
        "He had separated his theory into several parts to ensure each of them can be specific and each theory is proved by mathematical calculation. He also shows his mathematical steps in this paper. Besides the mathematical calculation, in order to enhance his demonstration and simplify the explanation, he used some graphs inside the process of proof, this enable this paper to be more academic."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWljXVNiNOvV",
        "colab_type": "text"
      },
      "source": [
        "The paper of Shannon was rated the basement of information theory. It has generated a huge influence on the development of modern communication and information theorems. On the other hand, the ‘A Mathematical Theory of Communication’ has been cited more than thousand times from past. This also proves from the side that this paper is highly technical thesis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHCZjx3hNQMD",
        "colab_type": "text"
      },
      "source": [
        "##Application and X-factor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPP9oCKfNWrC",
        "colab_type": "text"
      },
      "source": [
        "Shannon’s three theorems laid the foundation of information theory (AffeldtEmail, et al 2014), although they are just the theory calculated through math, they are still used in communication area. In the paper of Liew and Hanzo (2002), they claimed a theory of space-time coding and concatenated channel coding for wireless communication which are basing on the Shannon’s theorems. Besides the communication area, these theorems can also be applied in the computer area. The Shannon’s three theorems has shown the limitation of the information process, at the same time, they also point out the direction of development (Frank. 2002). For most of the database and information storage, the way they deal with message and compress data all following the theory presented by Professor Shannon. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFHK1bYGNYp9",
        "colab_type": "text"
      },
      "source": [
        "I believe the ‘A Mathematical theory of Communication’ can result in a good discussion. This paper has led to an effect on the modern communication technology, it causes a great repercussion when the paper published. This is definitely worth every researcher in related area to read."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sXy4dqjNb0F",
        "colab_type": "text"
      },
      "source": [
        "Shannon used mathematical steps to prove his theory. the assumption and formulas he use or set, or the logic while proving each theory are worth for researchers to discuss."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkaTzyonNgGt",
        "colab_type": "text"
      },
      "source": [
        "##Presentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfdbximCNi0T",
        "colab_type": "text"
      },
      "source": [
        "The presentation of the paper is high quality in my opinion. There are heading and subheading to indicate each different section, it is easy for readers to find each part and different arguments. The main points of the paper are proved through mathematical calculation, so there are many assumption and mathematical formulas. But it is still clean and organized. The argument and its proof process are shown within a good structure and any assumption related is list before the proof with explanation. Shannon’s three theorems are the basement of many area researches. So, I can conclude the argument of this paper is really deep and thoughtful. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAY-7vylNk2m",
        "colab_type": "text"
      },
      "source": [
        "##Reference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZaNAouiNm30",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "1.   M.P. Frank. 2002, ‘The physical limits of computing’, Computing in Science & Engineering, Vol.4, no.3.\n",
        "\n",
        "\n",
        "2.   R.AffeldtEmail,M Hagiwara,J Sénizergues, 2014, ‘Formalization of Shannon’s Theorems‘, Journal of Automated Reasoning, Vol 53,No.1, pp 63–103. \n",
        "\n",
        "\n",
        "3.   \n",
        "S. l Har-Peled, 2009, ‘Shannon’s theorem’, viewed 19 August 2019, \n",
        "< https://courses.engr.illinois.edu/cs573/fa2009/files/lec/28_shannon.pdf > \n",
        "\n",
        "\n",
        "4.   T.H. Liew, L. Hanzo. 2002, ‘Space-time codes and concatenated channel codes for wireless communications’, Proceedings of the IEEE, Vol.90, no.2\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}